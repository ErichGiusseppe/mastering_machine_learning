{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Hq739EyGb3y"
   },
   "source": [
    "## Mastering Machine Learning 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJkJsOuHGb30"
   },
   "source": [
    "### Clase 1: Introducción a redes neuronales en pytorch\n",
    "\n",
    "- Redes densas\n",
    "- Redes para regresión\n",
    "- Funciones de activación y pérdida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXCuT4WNIQRr"
   },
   "source": [
    "Empecemos importando numpy y pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XvZd5CxTGdcd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGg9_6DtITUc"
   },
   "source": [
    "Montemos el drive de google para leer archivos almacenados allí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbAZ5HecG14P"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbWocciXIZjU"
   },
   "source": [
    "Carguemos el archivo auto-mpg.data (disponible en Bloque Neón) usando pandas. Note que debemos incluir los nombres de las columnas, además de indicar los caracteres para separación, nas y comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrWIjZxQG-Pm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('gdrive/My Drive/25_mml/sesiones/auto-mpg.data',\n",
    "                 names=['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin'],\n",
    "                 sep=' ',\n",
    "                 na_values='?',\n",
    "                 comment='\\t',\n",
    "                 skipinitialspace=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It4_BrEgI6_w"
   },
   "source": [
    "Exploremos las primeras filas del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjBQLhr3INGC"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf3tQ4SdKQy7"
   },
   "source": [
    "- MPG: miles per gallon\n",
    "- Cylinders: # de cilindros\n",
    "- Displacement: volumen desplazado por los pistones\n",
    "- Horsepower: caballos de potencia\n",
    "- Weight: peso\n",
    "- Acceleration: aceleración\n",
    "- Model Year: año/modelo\n",
    "- Origin: 1:USA, 2:Europa, 3:Japón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRDlL9vAJAz1"
   },
   "source": [
    "Exploremos el tamaño del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeHyTPnEJC8f"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dONjz931JFhG"
   },
   "source": [
    "Identificamos NAs en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47pvp0jtJFKt"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLFDxYntJ-V6"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdrDznxmKEqU"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhM7A63WVL91"
   },
   "outputs": [],
   "source": [
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xj0X-3tVS6W"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ls8L1hRMQh4"
   },
   "source": [
    "Separamos los datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbel5_Oqc0Rq"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dADsWjtMTcS"
   },
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(df, train_size=0.8, random_state=100)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZOQNUy2jSwH"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TC9xJuiKMenc"
   },
   "outputs": [],
   "source": [
    "test = df.drop(train.index)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-H2PITXhMmcz"
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t58x12kjNrK7"
   },
   "source": [
    "Realicemos una exploración descriptiva de los datos, calculando inicialmente estadísticas de cada variable continua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ycw_T_PnNtmr"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obRp7Qr3M1gE"
   },
   "source": [
    "Exploremos relaciones bivariadas con pairplot de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QA4kCzEoNIc5"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAZexVxsM5Sm"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMdDgjyMSoi6"
   },
   "source": [
    "Calculemos la matriz de correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BxKu1MZOF0q"
   },
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaMThi75OMGs"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jMkg5O2iY9p"
   },
   "outputs": [],
   "source": [
    "numeric_cols = ['Cylinders', 'Displacement','Horsepower','Weight','Acceleration', 'Model Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAIEAMO7iid1"
   },
   "outputs": [],
   "source": [
    "train_norm , test_norm = train.copy(), test.copy()\n",
    "\n",
    "for col in numeric_cols:\n",
    "  mean = train[col].mean()\n",
    "  std = train[col].std()\n",
    "\n",
    "  train_norm[col] = ( train_norm[col] - mean) /std\n",
    "  test_norm[col] = (test_norm[col] - mean) /std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaA3_AZR5UJ_"
   },
   "outputs": [],
   "source": [
    "train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_aef6dM7smB"
   },
   "source": [
    "Codificación one-hot para Origin y generación de datos de entrada x_train y x_test, en formato tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWfRtq1-adig"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "# determinar número de categorías\n",
    "n_categories = len(set(train_norm['Origin']))\n",
    "\n",
    "# codificación one hot para Origin - train set\n",
    "origin_encoded = one_hot(torch.from_numpy(train_norm['Origin'].values % n_categories))\n",
    "x_train_numeric = torch.tensor(train_norm[numeric_cols].values)\n",
    "x_train = torch.cat([x_train_numeric, origin_encoded], 1).float()\n",
    "\n",
    "# codificación one hot para Origin - test set\n",
    "origin_encoded = one_hot(torch.from_numpy(test_norm['Origin'].values % n_categories))\n",
    "x_test_numeric = torch.tensor(test_norm[numeric_cols].values)\n",
    "x_test = torch.cat([x_test_numeric, origin_encoded], 1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_ZxWAsY70S-"
   },
   "source": [
    "Datos de salida en formato tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgyOHksx7fCF"
   },
   "outputs": [],
   "source": [
    "y_train = torch.tensor(train_norm['MPG'].values).float()\n",
    "y_test = torch.tensor(test_norm['MPG'].values).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33MzsfJM7_EN"
   },
   "source": [
    "Crear un Dataset y un DataLoader para el entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDoD5lhU8JgT"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "batch_size = 16\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99us1OTF8Q_B"
   },
   "source": [
    "Crear un primer modelo con dos capas ocultas de 8 y 4 neuronas (función de activación ReLU) y una salida lineal (regresión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bV1o4_rV8S7a"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "hidden_units = [8, 4]\n",
    "input_size = x_train.shape[1]\n",
    "\n",
    "all_layers = []\n",
    "for hidden_units_layer in hidden_units:\n",
    "  layer = nn.Linear(input_size, hidden_units_layer)\n",
    "  all_layers.append(layer)\n",
    "  all_layers.append(nn.ReLU())\n",
    "  input_size = hidden_units_layer\n",
    "\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 1))\n",
    "model = nn.Sequential(*all_layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4O1Kjlhb8_Id"
   },
   "source": [
    "Entrenar el modelo usando descenso del gradiente estocástico y función de pérdida MSE (mean squared error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zYFFJP49KQh"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 200\n",
    "log_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  loss_hist_train = 0\n",
    "  for x_batch, y_batch in train_dl:\n",
    "    pred = model(x_batch)[:,0]\n",
    "    loss = loss_fn(pred, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    loss_hist_train += loss.item()\n",
    "\n",
    "  if epoch % log_epochs == 0:\n",
    "    print(f'Epoch {epoch} Loss {loss_hist_train/len(train_dl):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdPegyO_9wm5"
   },
   "source": [
    "Predicción de un nuevo dato de prueba y evaluación con MSE y MAE (mean absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peFeaNJl9zrR"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  pred = model(x_test.float())[:,0]\n",
    "  loss = loss_fn(pred, y_test)\n",
    "  print(f'Test MSE: {loss.item():.4f}')\n",
    "  print(f'Test MAE: {nn.L1Loss()(pred,y_test).item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
